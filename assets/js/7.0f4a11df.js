(window.webpackJsonp=window.webpackJsonp||[]).push([[7],{177:function(t,s,a){"use strict";a.r(s);var n=a(0),e=Object(n.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("div",{staticClass:"content"},[a("h1",[t._v("Tensorflow Syntax")]),a("h2",{attrs:{id:"session"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#session","aria-hidden":"true"}},[t._v("#")]),t._v(" Session")]),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v("# Method 1")]),t._v("\nsess "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Session"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresult "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dot_operation"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("# Method 2")]),t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("with")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Session"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token keyword"}},[t._v("as")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    result "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dot_operation"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# Run multiple ops")]),t._v("\n    z1_value"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" z2_value "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("z1"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" z2"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br")])]),a("h2",{attrs:{id:"placeholder"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#placeholder","aria-hidden":"true"}},[t._v("#")]),t._v(" Placeholder")]),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("x1 "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dtype"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" shape"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny1 "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dtype"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" shape"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token boolean"}},[t._v("None")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nz1 "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" x1 "),a("span",{attrs:{class:"token operator"}},[t._v("+")]),t._v(" y1\nx2 "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dtype"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" shape"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("2")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny2 "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dtype"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" shape"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("2")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nz2 "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("matmul"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x2"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y2"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br")])]),a("h2",{attrs:{id:"activation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#activation","aria-hidden":"true"}},[t._v("#")]),t._v(" Activation")]),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("x "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linspace"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token operator"}},[t._v("-")]),a("span",{attrs:{class:"token number"}},[t._v("5")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("5")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("200")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("     "),a("span",{attrs:{class:"token comment"}},[t._v("# x data, shape=(100, 1)")]),t._v("\ny_relu "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny_sigmoid "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sigmoid"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny_tanh "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tanh"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny_softplus "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softplus"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny_softmax "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("softmax"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny_relu"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_sigmoid"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_tanh"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_softplus"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_softmax "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("y_relu"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_sigmoid"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_tanh"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_softplus"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_softmax"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br")])]),a("p",[a("img",{attrs:{src:"/images/activation-syntax.png",alt:"activation-syntax.png"}})]),a("h2",{attrs:{id:"simple-regression"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#simple-regression","aria-hidden":"true"}},[t._v("#")]),t._v(" Simple Regression")]),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("tf_x "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("     "),a("span",{attrs:{class:"token comment"}},[t._v("# input x")]),t._v("\ntf_y "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("     "),a("span",{attrs:{class:"token comment"}},[t._v("# input y")]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("# one hidden fully connected layer")]),t._v("\nl1 "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf_x"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("10")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("     "),a("span",{attrs:{class:"token comment"}},[t._v("# hidden layer")]),t._v("\noutput "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("l1"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("                "),a("span",{attrs:{class:"token comment"}},[t._v("# output layer => output one float number")]),t._v("\n\nloss "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("losses"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean_squared_error"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf_y"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" output"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{attrs:{class:"token comment"}},[t._v("# compute loss")]),t._v("\noptimizer "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("GradientDescentOptimizer"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token number"}},[t._v("0.5")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntrain_op "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" optimizer"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("minimize"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsess "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Session"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("                            "),a("span",{attrs:{class:"token comment"}},[t._v("# control training and others")]),t._v("\nsess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("global_variables_initializer"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),a("span",{attrs:{class:"token comment"}},[t._v("# initialize var in graph")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" step "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("range")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("100")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# train and net output")]),t._v("\n    _"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" l"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pred "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("train_op"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" output"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("tf_x"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" x"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf_y"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" y"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),a("span",{attrs:{class:"token comment"}},[t._v("# plot and show learning process")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" step "),a("span",{attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("5")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        plt"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cla"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("# clear current axis (clear previous drawn line)")]),t._v("\n        plt"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        plt"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pred"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'r-'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lw"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token number"}},[t._v("5")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        plt"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("0.5")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'Loss=%.4f'")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("%")]),t._v(" l"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fontdict"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{attrs:{class:"token string"}},[t._v("'size'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("20")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'color'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'red'")]),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        plt"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pause"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("0.1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nplt"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br")])]),a("p",[a("img",{attrs:{src:"/images/simple_regression.png",alt:"simple_regression.png"}})]),a("h2",{attrs:{id:"simple-classification"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#simple-classification","aria-hidden":"true"}},[t._v("#")]),t._v(" Simple Classification")]),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("tf_x "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("float32"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   "),a("span",{attrs:{class:"token comment"}},[t._v("# input x")]),t._v("\ntf_y "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("int32"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("     "),a("span",{attrs:{class:"token comment"}},[t._v("# input y")]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("# neural network layers")]),t._v("\nl1 "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf_x"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("10")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("          "),a("span",{attrs:{class:"token comment"}},[t._v("# hidden layer")]),t._v("\noutput "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("l1"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("2")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("                     "),a("span",{attrs:{class:"token comment"}},[t._v("# output layer")]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("# Use cross entropy to compute loss")]),t._v("\nloss "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("losses"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sparse_softmax_cross_entropy"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("labels"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("tf_y"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" logits"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("output"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\noptimizer "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("GradientDescentOptimizer"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learning_rate"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token number"}},[t._v("0.05")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntrain_op "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" optimizer"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("minimize"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("# Use accuracy to measure performance")]),t._v("\n"),a("span",{attrs:{class:"token comment"}},[t._v("# return (acc, update_op), and creates 2 local variables")]),t._v("\naccuracy "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metrics"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("accuracy"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("  \n    labels"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("squeeze"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf_y"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" predictions"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("argmax"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("output"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" axis"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("# control training and others")]),t._v("\nsess "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Session"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ninit_op "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("group"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("global_variables_initializer"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                   tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("local_variables_initializer"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("init_op"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" step "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("range")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("100")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# train and net output")]),t._v("\n    _"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" acc"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pred "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("train_op"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" accuracy"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" output"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("tf_x"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" x"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf_y"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" y"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),a("span",{attrs:{class:"token comment"}},[t._v("# plot and show learning process")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" step "),a("span",{attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("5")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        plt"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cla"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        plt"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scatter"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" c"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v("pred"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("argmax"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" s"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token number"}},[t._v("100")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lw"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cmap"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token string"}},[t._v("'RdYlGn'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        plt"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("1.5")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("-")]),a("span",{attrs:{class:"token number"}},[t._v("4")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'Accuracy=%.2f'")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("%")]),t._v(" acc"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fontdict"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{attrs:{class:"token string"}},[t._v("'size'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("20")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'color'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'red'")]),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        plt"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pause"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("0.1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br"),a("span",{staticClass:"line-number"},[t._v("29")]),a("br"),a("span",{staticClass:"line-number"},[t._v("30")]),a("br"),a("span",{staticClass:"line-number"},[t._v("31")]),a("br"),a("span",{staticClass:"line-number"},[t._v("32")]),a("br"),a("span",{staticClass:"line-number"},[t._v("33")]),a("br")])]),a("p",[a("img",{attrs:{src:"/images/simple_classification.png",alt:"simple_classification.png"}})]),a("hr"),a("p",[a("strong",[t._v("softmax_cross_entropy")]),t._v(" vs. "),a("strong",[t._v("sparse_softmax_cross_entropy")])]),a("table",[a("thead",[a("tr",[a("th"),a("th",[a("code",[t._v("softmax_cross_entropy")])]),a("th",[a("code",[t._v("sparse_softmax_cross_entropy")])])])]),a("tbody",[a("tr",[a("td",[t._v("Label Type")]),a("td",[t._v("int32 / int64")]),a("td",[t._v("float32 / float64")])]),a("tr",[a("td",[t._v("Label Shape")]),a("td",[t._v("(batch_size, n_classes)")]),a("td",[t._v("(batch_size)")])]),a("tr",[a("td",[t._v("Label Form")]),a("td",[t._v("Any Integer")]),a("td",[t._v("One-hot Encoding")])])])]),a("h2",{attrs:{id:"save-load-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#save-load-model","aria-hidden":"true"}},[t._v("#")]),t._v(" Save / Load Model")]),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{attrs:{class:"token comment"}},[t._v("# SAVE")]),t._v("\nsaver "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Saver"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsess "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Session"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{attrs:{class:"token comment"}},[t._v("# sess.run ...")]),t._v("\n"),a("span",{attrs:{class:"token comment"}},[t._v("# write_meta_graph is not recommended (can be very large)")]),t._v("\nsaver"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("save"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'./<dir>/<file_prefix>'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" write_meta_graph"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token boolean"}},[t._v("False")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{attrs:{class:"token comment"}},[t._v("# LOAD")]),t._v("\nsaver "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Saver"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsaver"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("restore"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token string"}},[t._v("'./<dir>/<file_prefix>'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{attrs:{class:"token comment"}},[t._v("# sess.run ...")]),t._v("\n\nsess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'w1:0'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("# run specific operation")]),t._v("\nw1 "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" graph"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_tensor_by_name"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'w1:0'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{attrs:{class:"token comment"}},[t._v("# get original tensor/operation")]),t._v("\n")])]),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br")])]),a("h2",{attrs:{id:"tensorboard"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tensorboard","aria-hidden":"true"}},[t._v("#")]),t._v(" Tensorboard")]),a("p",[t._v("Run tensorboard with "),a("code",[t._v("tensorboard --logdir path/to/logdir")])]),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("summary"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("histogram"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'pred'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" output"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("summary"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scalar"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'loss'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("     "),a("span",{attrs:{class:"token comment"}},[t._v("# add loss to scalar summary")]),t._v("\nmerge_op "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("summary"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("merge_all"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nwriter "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("summary"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("FileWriter"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'./log'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("graph"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("     "),a("span",{attrs:{class:"token comment"}},[t._v("# write to file")]),t._v("\n\n"),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" step "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("range")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("100")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# train and net output")]),t._v("\n    _"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" result "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("train_op"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" merge_op"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("tf_x"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" x"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf_y"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" y"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    writer"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_summary"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" step"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])]),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br")])]),a("h2",{attrs:{id:"dataset"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dataset","aria-hidden":"true"}},[t._v("#")]),t._v(" Dataset")]),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("tfx "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("npx_train"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dtype"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" npx_train"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntfy "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("placeholder"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("npy_train"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dtype"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" npy_train"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndataset "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dataset"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_tensor_slices"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tfx"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tfy"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndataset "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shuffle"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("buffer_size"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token number"}},[t._v("1000")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndataset "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("batch"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("32")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndataset "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("repeat"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("3")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{attrs:{class:"token comment"}},[t._v("# repeat epochs, if not specified, default is 1 epoch")]),t._v("\niterator "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" dataset"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("make_initializable_iterator"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbx"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" by "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" iterator"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_next"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{attrs:{class:"token comment"}},[t._v("# returns get_next operation")]),t._v("\nl1 "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bx"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("10")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nn"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("relu"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nout "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dense"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("l1"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" npy"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{attrs:{class:"token number"}},[t._v("1")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nloss "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("losses"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean_squared_error"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("by"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" out"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntrain "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("GradientDescentOptimizer"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token number"}},[t._v("0.1")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("minimize"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nsess "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Session"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("iterator"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("initializer"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("global_variables_initializer"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n         feed_dict"),a("span",{attrs:{class:"token operator"}},[t._v("=")]),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("tfx"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" npx_train"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tfy"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" npy_train"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nN "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("200")]),t._v("\n"),a("span",{attrs:{class:"token comment"}},[t._v("# Iterate times: min(N, num_train / batch_size * epochs)")]),t._v("\n"),a("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" step "),a("span",{attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{attrs:{class:"token builtin"}},[t._v("range")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("N"),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("try")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token comment"}},[t._v("# data is embedded into `train`")]),t._v("\n        _"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" trainl "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("train"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" loss"),a("span",{attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" step "),a("span",{attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("10")]),t._v(" "),a("span",{attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{attrs:{class:"token number"}},[t._v("0")]),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{attrs:{class:"token comment"}},[t._v("# run loss op on test set")]),t._v("\n            testl "),a("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" sess"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run"),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("bx"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" npx_test"),a("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" by"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" npy_test"),a("span",{attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{attrs:{class:"token comment"}},[t._v("# If N > num_train / batch_size * epochs, this exception will be raised")]),t._v("\n    "),a("span",{attrs:{class:"token keyword"}},[t._v("except")]),t._v(" tf"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("errors"),a("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("OutOfRangeError"),a("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("print")]),a("span",{attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{attrs:{class:"token string"}},[t._v("'Finished the last epoch.'")]),a("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{attrs:{class:"token keyword"}},[t._v("break")]),t._v("\n")])]),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br"),a("span",{staticClass:"line-number"},[t._v("24")]),a("br"),a("span",{staticClass:"line-number"},[t._v("25")]),a("br"),a("span",{staticClass:"line-number"},[t._v("26")]),a("br"),a("span",{staticClass:"line-number"},[t._v("27")]),a("br"),a("span",{staticClass:"line-number"},[t._v("28")]),a("br"),a("span",{staticClass:"line-number"},[t._v("29")]),a("br"),a("span",{staticClass:"line-number"},[t._v("30")]),a("br"),a("span",{staticClass:"line-number"},[t._v("31")]),a("br"),a("span",{staticClass:"line-number"},[t._v("32")]),a("br")])])])}],!1,null,null,null);s.default=e.exports}}]);